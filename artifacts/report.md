# Rust async programming

## Summary

Research Summary for "Rust async programming" (comprehensive strategy):

Found 3 relevant findings.

Key findings:
- Finding from Fundamentals of Asynchronous Programming: Async, Await ... - Learn Rust: Fundamentals of Asynchronous Programming: Async, Await, Futures, and Streams - The Rust Programming Language Keyboard shortcuts Press ← or → to navigate between chapters Press S or / to search in the book Press ? to show this help Press Esc to hide this help Auto Light Rust Coal Navy Ayu The Rust Programming Language Fundamentals of Asynchronous Programming: Async, Await, Futures, and Streams Many operations we ask the computer to do can take a while to finish. It would be nice if we could do something else while we are waiting for those long-running processes to complete. Modern computers offer two techniques for working on more than one operation at a time: parallelism and concurrency. Once we start writing programs that involve parallel or concurrent operations, though, we quickly encounter new challenges inherent to asynchronous programming , where operations may not finish sequentially in the order they were started. This chapter builds on Chapter 16’s use of threads for parallelism and concurrency by introducing an alternative approach to asynchronous programming: Rust’s Futures, Streams, the async and await syntax that supports them, and the tools for managing and coordinating between asynchronous operations. Let’s consider an example. Say you’re exporting a video you’ve created of a family celebration, an operation that could take anywhere from minutes to hours. The video export will use as much CPU and GPU power as it can. If you had only one CPU core and your operating system didn’t pause that export until it completed—that is, if it executed the export synchronously —you couldn’t do anything else on your computer while that task was running. That would be a pretty frustrating experience. Fortunately, your computer’s operating system can, and does, invisibly interrupt the export often enough to let you get other work done simultaneously. Now say you’re downloading a video shared by someone else, which can also take a while but does not take up as much CPU time. In this case, the CPU has to wait for data to arrive from the network. While you can start reading the data once it starts to arrive, it might take some time for all of it to show up. Even once the data is all present, if the video is quite large, it could take at least a second or two to load it all. That might not sound like much, but it’s a very long time for a modern processor, which can perform billions of operations every second. Again, your operating system will invisibly interrupt your program to allow the CPU to perform other work while waiting for the network call to finish. The video export is an example of a CPU-bound or compute-bound operation. It’s limited by the computer’s potential data processing speed within the CPU or GPU, and how much of that speed it can dedicate to the operation. The video download is an example of an IO-bound operation, because it’s limited by the speed of the computer’s input and output ; it can only go as fast as the data can be sent across the network. In both of these examples, the operating system’s invisible interrupts provide a form of concurrency. That concurrency happens only at the level of the entire program, though: the operating system interrupts one program to let other programs get work done. In many cases, because we understand our programs at a much more granular level than the operating system does, we can spot opportunities for concurrency that the operating system can’t see. For example, if we’re building a tool to manage file downloads, we should be able to write our program so that starting one download won’t lock up the UI, and users should be able to start multiple downloads at the same time. Many operating system APIs for interacting with the network are blocking , though; that is, they block the program’s progress until the data they’re processing is completely ready. Note: This is how most function calls work, if you think about it. However, the term blocking is usually reserved for function calls that interact with files, the network, or other resources on the computer, because those are the cases where an individual program would benefit from the operation being non -blocking. We could avoid blocking our main thread by spawning a dedicated thread to download each file. However, the overhead of those threads would eventually become a problem. It would be preferable if the call didn’t block in the first place. It would also be better if we could write in the same direct style we use in blocking code, similar to this: let data = fetch_data_from(url).await; println!("{data}"); That is exactly what Rust’s async (short for asynchronous ) abstraction gives us. In this chapter, you’ll learn all about async as we cover the following topics: How to use Rust’s async and await syntax How to use the async model to solve some of the same challenges we looked at in Chapter 16 How multithreading and async provide complementary solutions, that you can combine in many cases Before we see how async works in practice, though, we need to take a short detour to discuss the differences between parallelism and concurrency. Parallelism and Concurrency We’ve treated parallelism and concurrency as mostly interchangeable so far. Now we need to distinguish between them more precisely, because the differences will show up as we start working. Consider the different ways a team could split up work on a software project. You could assign a single member multiple tasks, assign each member one task, or use a mix of the two approaches. When an individual works on several different tasks before any of them is complete, this is concurrency . Maybe you have two different projects checked out on your computer, and when you get bored or stuck on one project, you switch to the other. You’re just one person, so you can’t make progress on both tasks at the exact same time, but you can multi-task, making progress on one at a time by switching between them (see Figure 17-1). Figure 17-1: A concurrent workflow, switching between Task A and Task B When the team splits up a group of tasks by having each member take one task and work on it alone, this is parallelism . Each person on the team can make progress at the exact same time (see Figure 17-2). Figure 17-2: A parallel workflow, where work happens on Task A and Task B independently In both of these workflows, you might have to coordinate between different tasks. Maybe you thought the task assigned to one person was totally independent from everyone else’s work, but it actually requires another person on the team to finish their task first. Some of the work could be done in parallel, but some of it was actually serial : it could only happen in a series, one task after the other, as in Figure 17-3. Figure 17-3: A partially parallel workflow, where work happens on Task A and Task B independently until Task A3 is blocked on the results of Task B3. Likewise, you might realize that one of your own tasks depends on another of your tasks. Now your concurrent work has also become serial. Parallelism and concurrency can intersect with each other, too. If you learn that a colleague is stuck until you finish one of your tasks, you’ll probably focus all your efforts on that task to “unblock” your colleague. You and your coworker are no longer able to work in parallel, and you’re also no longer able to work concurrently on your own tasks. The same basic dynamics come into play with software and hardware. On a machine with a single CPU core, the CPU can perform only one operation at a time, but it can still work concurrently. Using tools such as threads, processes, and async, the computer can pause one activity and switch to others before eventually cycling back to that first activity again. On a machine with multiple CPU cores, it can also do work in parallel. One core can be performing one task while another core performs a completely unrelated one, and those operations actually happen at the same time. When working with async in Rust, we’re always dealing with concurrency. Depending on the hardware, the operating system, and the async runtime we are using (more on async runtimes shortly), that concurrency may also use parallelism under the hood. Now, let’s dive into how async programming in Rust actually works. (confidence: 0.80)
- Finding from Introduction - Async programming in Rust with async-std: Introduction - Async programming in Rust with async-std 1. Introduction 1.1. Welcome to async-std! 1.2. std::future and futures-rs 1.3. Stability guarantees 2. Async concepts using async-std 2.1. Futures 2.2. Tasks 2.3. Async read/write 2.4. Streams and Channels 3. Tutorial: Implementing a chat 3.1. Specification and Getting started 3.2. Writing an Accept Loop 3.3. Receiving Messages 3.4. Sending Messages 3.5. Connecting Readers and Writers 3.6. All Together 3.7. Clean Shutdown 3.8. Handling Disconnection 3.9. Implementing a Client 4. Async Patterns 4.1. TODO: Collected Small Patterns 4.2. Production-Ready Accept Loop 5. Security practices 5.1. Security Disclosures and Policy 6. Glossary Light (default) Rust Coal Navy Ayu Async programming in Rust with async-std Introduction This book serves as high-level documentation for async-std and a way of learning async programming in Rust through it. As such, it focuses on the async-std API and the task model it gives you. Please note that the Rust project provides its own book on asynchronous programming, called &quot;Asynchronous Programming in Rust&quot; , which we highly recommend reading along with this book, as it provides a different, wider view on the topic. (confidence: 0.80)
- Finding from Async/Await in Rust: A Beginner&#x27;s Guide | by Leapcell | Medium: Async/Await in Rust: A Beginner’s Guide | by Leapcell | Medium Sitemap Open in app Sign up Sign in Medium Logo Write Search Sign up Sign in Async/Await in Rust: A Beginner’s Guide An introduction to Rust’s async/await, explaining Futures, executors, and concurrency with practical examples. Leapcell 6 min read · Mar 20, 2025 -- Listen Share Async/.await in Rust Asynchronous Programming async/.await is a built-in Rust language feature that allows us to write asynchronous code in a synchronous style. Let’s learn how to use the async/.await keywords through examples. Before we begin, we need to introduce the futures package. Edit the Cargo.toml file and add the following content: [dependencies] futures = &quot;0.3&quot; Using async to Create an Asynchronous Future Simply put, the async keyword can be used to create the following types of Future : Define a function: async fn Define a block: async {} For example, an async function: async fn hello_world() { ... } The async keyword modifies the function prototype to return a Future trait object. It then wraps the execution result in a new Future and returns it, roughly equivalent to: fn hello_world() -&gt; impl Future&lt;Output = ()&gt; { async { ... } } Note: The async block implements an anonymous Future trait object, encapsulating a Generator , which is a Future -implementing generator. A Generator essentially acts as a state machine. When any operation inside an async block returns Poll::Pending , the generator calls yield , relinquishing execution. Once resumed, the generator continues execution until all code completes, meaning the state machine enters the Complete state and returns Poll::Ready , signaling that the Future has finished execution. A code block marked with async is converted into a state machine that implements the Future trait. Unlike synchronous calls that block the current thread, when a Future encounters a blocking operation, it relinquishes control of the current thread, waiting for the execution result of other Future s. A Future needs to run on an executor. For example, block_on is an executor that blocks the current thread: // block_on blocks the current thread until the specified Future completes execution. // This approach is simple and direct, but other runtime executors provide more sophisticated behaviors, // such as using join to schedule multiple futures on the same thread. use futures::executor::block_on; async fn hello_world() { println!(&quot;hello, world!&quot;); } fn main() { let future = hello_world(); // Returns a Future, so no output is printed yet block_on(future); // Executes the Future and waits for it to complete; &quot;hello, world!&quot; is then printed } Using await to Wait for Another Asynchronous Future to Complete In the main function above, we used the block_on executor to wait for the Future to complete, making the code appear synchronous. But what if you need to call an async fn inside another async fn and wait for its completion before executing subsequent code? For example: use futures::executor::block_on; async fn hello_world() { // Directly calling another async function inside an async function-will this work? hello_cat(); println!(&quot;hello, world!&quot;); } async fn hello_cat() { println!(&quot;hello, kitty!&quot;); } fn main() { let future = hello_world(); block_on(future); } Here, in the hello_world async function, we first call another async function hello_cat and then print &quot;hello, world!&quot; . Let&#x27;s check the output: warning: unused implementer of `futures::Future` that must be used --&gt; src/main.rs:6:5 | 6 | hello_cat(); | ^^^^^^^^^^^^ = note: futures do nothing unless you `.await` or poll them ... hello, world! As expected, we executed the Future in main using block_on , but the Future returned by hello_cat was never executed. Fortunately, the compiler provides a friendly warning: &quot;Futures do nothing unless you .await or poll them.&quot; There are two solutions: Use .await syntax. Manually poll the Future (which is more complex, so we won’t cover it here). Let’s modify the code using .await : use futures::executor::block_on; async fn hello_world() { hello_cat().await; println!(&quot;hello, world!&quot;); } async fn hello_cat() { println!(&quot;hello, kitty!&quot;); } fn main() { let future = hello_world(); block_on(future); } After adding .await to hello_cat() , the output changes significantly: hello, kitty! hello, world! The output order now strictly follows the code order. This means that we achieved asynchronous execution while maintaining a sequential coding style. This approach is simple, efficient, and eliminates callback hell. Internally, every .await acts like an executor, repeatedly polling the Future state. If it returns Pending , it calls yield . Otherwise, it exits the loop and completes the Future execution. The logic is roughly as follows: loop { match some_future.poll() { Pending =&gt; yield, Ready(x) =&gt; break } } In short, using .await inside an async fn allows waiting for another asynchronous call to complete. However, unlike block_on , .await does not block the current thread. Instead, it asynchronously waits for Future A to complete. While waiting, the thread can continue executing other Future B instances, enabling concurrency. An Example Consider a scenario of singing and dancing. Without .await , the implementation might look like this: use futures::executor::block_on; struct Song { author: String, name: String, } async fn learn_song() -&gt; Song { Song { author: &quot;Rick Astley&quot;.to_string(), name: String::from(&quot;Never Gonna Give You Up&quot;), } } async fn sing_song(song: Song) { println!( &quot;Performing {}&#x27;s {} ~ {}&quot;, song.author, song.name, &quot;Never gonna let you down&quot; ); } async fn dance() { println!(&quot;Dancing along to the song&quot;); } fn main() { let song = block_on(learn_song()); // First blocking call block_on(sing_song(song)); // Second blocking call block_on(dance()); // Third blocking call } This code runs correctly but requires three consecutive blocking calls, completing one task at a time. In reality, we could sing and dance simultaneously: use futures::executor::block_on; struct Song { author: String, name: String, } async fn learn_song() -&gt; Song { Song { author: &quot;Rick Astley&quot;.to_string(), name: String::from(&quot;Never Gonna Give You Up&quot;), } } async fn sing_song(song: Song) { println!( &quot;Performing {}&#x27;s {} ~ {}&quot;, song.author, song.name, &quot;Never gonna let you down&quot; ); } async fn dance() { println!(&quot;Dancing along to the song&quot;); } async fn learn_and_sing() { let song = learn_song().await; sing_song(song).await; } async fn async_main() { let f1 = learn_and_sing(); let f2 = dance(); // The join! macro runs multiple futures concurrently futures::join!(f1, f2); } fn main() { block_on(async_main()); } Here, learning and singing have a strict order, but both can coexist with dancing. Without .await , using block_on(learn_song()) would block the current thread, preventing any other tasks, including dancing. Thus, .await is crucial for asynchronous programming in Rust. It allows multiple tasks to run concurrently on the same thread instead of executing sequentially. Conclusion async/.await is Rust&#x27;s built-in tool for writing asynchronous functions that look like synchronous code. async converts a code block into a state machine that implements the Future trait, which must run on an executor. Instead of blocking an entire thread, a Future yields control, allowing other Future s to execute. Key takeaways: Future represents a task that yields a value in the future. async creates a Future . .await polls a Future , waiting for it to complete. Executors (like block_on ) manage and execute Future s. Rust’s async is zero-cost: no heap allocation or dynamic dispatch. Rust does not include a built-in async runtime; third-party libraries like tokio , async-std , and smol provide this functionality. In summary, async/.await enables efficient, concurrent task execution in Rust, eliminating callback hell and making asynchronous programming intuitive. We are Leapcell, your top choice for hosting Rust projects. Leapcell is the Next-Gen Serverless Platform for Web Hosting, Async Tasks, and Redis: Multi-Language Support Develop with Node.js, Python, Go, or Rust. Deploy unlimited projects for free pay only for usage — no requests, no charges. Unbeatable Cost Efficiency Pay-as-you-go with no idle charges. Example: $25 supports 6.94M requests at a 60ms average response time. Streamlined Developer Experience Intuitive UI for effortless setup. Fully automated CI/CD pipelines and GitOps integration. Real-time metrics and logging for actionable insights. Effortless Scalability and High Performance Auto-scaling to handle high concurrency with ease. Zero operational overhead — just focus on building. Explore more in the Documentation ! Follow us on X: @LeapcellHQ Read on our blog Web Development Programming Backend Rust -- -- Written by Leapcell 395 followers · 1 following leapcell.io , web hosting / async task / redis No responses yet Help Status About Careers Press Blog Privacy Rules Terms Text to speech (confidence: 0.80)

## Metadata

- **Strategy**: Comprehensive
- **Depth**: 1
- **Sources**: 3
- **Diversity Score**: 1.00
- **Confidence**: High

## Findings

### Finding 1

Finding from Fundamentals of Asynchronous Programming: Async, Await ... - Learn Rust: Fundamentals of Asynchronous Programming: Async, Await, Futures, and Streams - The Rust Programming Language Keyboard shortcuts Press ← or → to navigate between chapters Press S or / to search in the book Press ? to show this help Press Esc to hide this help Auto Light Rust Coal Navy Ayu The Rust Programming Language Fundamentals of Asynchronous Programming: Async, Await, Futures, and Streams Many operations we ask the computer to do can take a while to finish. It would be nice if we could do something else while we are waiting for those long-running processes to complete. Modern computers offer two techniques for working on more than one operation at a time: parallelism and concurrency. Once we start writing programs that involve parallel or concurrent operations, though, we quickly encounter new challenges inherent to asynchronous programming , where operations may not finish sequentially in the order they were started. This chapter builds on Chapter 16’s use of threads for parallelism and concurrency by introducing an alternative approach to asynchronous programming: Rust’s Futures, Streams, the async and await syntax that supports them, and the tools for managing and coordinating between asynchronous operations. Let’s consider an example. Say you’re exporting a video you’ve created of a family celebration, an operation that could take anywhere from minutes to hours. The video export will use as much CPU and GPU power as it can. If you had only one CPU core and your operating system didn’t pause that export until it completed—that is, if it executed the export synchronously —you couldn’t do anything else on your computer while that task was running. That would be a pretty frustrating experience. Fortunately, your computer’s operating system can, and does, invisibly interrupt the export often enough to let you get other work done simultaneously. Now say you’re downloading a video shared by someone else, which can also take a while but does not take up as much CPU time. In this case, the CPU has to wait for data to arrive from the network. While you can start reading the data once it starts to arrive, it might take some time for all of it to show up. Even once the data is all present, if the video is quite large, it could take at least a second or two to load it all. That might not sound like much, but it’s a very long time for a modern processor, which can perform billions of operations every second. Again, your operating system will invisibly interrupt your program to allow the CPU to perform other work while waiting for the network call to finish. The video export is an example of a CPU-bound or compute-bound operation. It’s limited by the computer’s potential data processing speed within the CPU or GPU, and how much of that speed it can dedicate to the operation. The video download is an example of an IO-bound operation, because it’s limited by the speed of the computer’s input and output ; it can only go as fast as the data can be sent across the network. In both of these examples, the operating system’s invisible interrupts provide a form of concurrency. That concurrency happens only at the level of the entire program, though: the operating system interrupts one program to let other programs get work done. In many cases, because we understand our programs at a much more granular level than the operating system does, we can spot opportunities for concurrency that the operating system can’t see. For example, if we’re building a tool to manage file downloads, we should be able to write our program so that starting one download won’t lock up the UI, and users should be able to start multiple downloads at the same time. Many operating system APIs for interacting with the network are blocking , though; that is, they block the program’s progress until the data they’re processing is completely ready. Note: This is how most function calls work, if you think about it. However, the term blocking is usually reserved for function calls that interact with files, the network, or other resources on the computer, because those are the cases where an individual program would benefit from the operation being non -blocking. We could avoid blocking our main thread by spawning a dedicated thread to download each file. However, the overhead of those threads would eventually become a problem. It would be preferable if the call didn’t block in the first place. It would also be better if we could write in the same direct style we use in blocking code, similar to this: let data = fetch_data_from(url).await; println!("{data}"); That is exactly what Rust’s async (short for asynchronous ) abstraction gives us. In this chapter, you’ll learn all about async as we cover the following topics: How to use Rust’s async and await syntax How to use the async model to solve some of the same challenges we looked at in Chapter 16 How multithreading and async provide complementary solutions, that you can combine in many cases Before we see how async works in practice, though, we need to take a short detour to discuss the differences between parallelism and concurrency. Parallelism and Concurrency We’ve treated parallelism and concurrency as mostly interchangeable so far. Now we need to distinguish between them more precisely, because the differences will show up as we start working. Consider the different ways a team could split up work on a software project. You could assign a single member multiple tasks, assign each member one task, or use a mix of the two approaches. When an individual works on several different tasks before any of them is complete, this is concurrency . Maybe you have two different projects checked out on your computer, and when you get bored or stuck on one project, you switch to the other. You’re just one person, so you can’t make progress on both tasks at the exact same time, but you can multi-task, making progress on one at a time by switching between them (see Figure 17-1). Figure 17-1: A concurrent workflow, switching between Task A and Task B When the team splits up a group of tasks by having each member take one task and work on it alone, this is parallelism . Each person on the team can make progress at the exact same time (see Figure 17-2). Figure 17-2: A parallel workflow, where work happens on Task A and Task B independently In both of these workflows, you might have to coordinate between different tasks. Maybe you thought the task assigned to one person was totally independent from everyone else’s work, but it actually requires another person on the team to finish their task first. Some of the work could be done in parallel, but some of it was actually serial : it could only happen in a series, one task after the other, as in Figure 17-3. Figure 17-3: A partially parallel workflow, where work happens on Task A and Task B independently until Task A3 is blocked on the results of Task B3. Likewise, you might realize that one of your own tasks depends on another of your tasks. Now your concurrent work has also become serial. Parallelism and concurrency can intersect with each other, too. If you learn that a colleague is stuck until you finish one of your tasks, you’ll probably focus all your efforts on that task to “unblock” your colleague. You and your coworker are no longer able to work in parallel, and you’re also no longer able to work concurrently on your own tasks. The same basic dynamics come into play with software and hardware. On a machine with a single CPU core, the CPU can perform only one operation at a time, but it can still work concurrently. Using tools such as threads, processes, and async, the computer can pause one activity and switch to others before eventually cycling back to that first activity again. On a machine with multiple CPU cores, it can also do work in parallel. One core can be performing one task while another core performs a completely unrelated one, and those operations actually happen at the same time. When working with async in Rust, we’re always dealing with concurrency. Depending on the hardware, the operating system, and the async runtime we are using (more on async runtimes shortly), that concurrency may also use parallelism under the hood. Now, let’s dive into how async programming in Rust actually works.

**Confidence**: 0.80

### Finding 2

Finding from Introduction - Async programming in Rust with async-std: Introduction - Async programming in Rust with async-std 1. Introduction 1.1. Welcome to async-std! 1.2. std::future and futures-rs 1.3. Stability guarantees 2. Async concepts using async-std 2.1. Futures 2.2. Tasks 2.3. Async read/write 2.4. Streams and Channels 3. Tutorial: Implementing a chat 3.1. Specification and Getting started 3.2. Writing an Accept Loop 3.3. Receiving Messages 3.4. Sending Messages 3.5. Connecting Readers and Writers 3.6. All Together 3.7. Clean Shutdown 3.8. Handling Disconnection 3.9. Implementing a Client 4. Async Patterns 4.1. TODO: Collected Small Patterns 4.2. Production-Ready Accept Loop 5. Security practices 5.1. Security Disclosures and Policy 6. Glossary Light (default) Rust Coal Navy Ayu Async programming in Rust with async-std Introduction This book serves as high-level documentation for async-std and a way of learning async programming in Rust through it. As such, it focuses on the async-std API and the task model it gives you. Please note that the Rust project provides its own book on asynchronous programming, called &quot;Asynchronous Programming in Rust&quot; , which we highly recommend reading along with this book, as it provides a different, wider view on the topic.

**Confidence**: 0.80

### Finding 3

Finding from Async/Await in Rust: A Beginner&#x27;s Guide | by Leapcell | Medium: Async/Await in Rust: A Beginner’s Guide | by Leapcell | Medium Sitemap Open in app Sign up Sign in Medium Logo Write Search Sign up Sign in Async/Await in Rust: A Beginner’s Guide An introduction to Rust’s async/await, explaining Futures, executors, and concurrency with practical examples. Leapcell 6 min read · Mar 20, 2025 -- Listen Share Async/.await in Rust Asynchronous Programming async/.await is a built-in Rust language feature that allows us to write asynchronous code in a synchronous style. Let’s learn how to use the async/.await keywords through examples. Before we begin, we need to introduce the futures package. Edit the Cargo.toml file and add the following content: [dependencies] futures = &quot;0.3&quot; Using async to Create an Asynchronous Future Simply put, the async keyword can be used to create the following types of Future : Define a function: async fn Define a block: async {} For example, an async function: async fn hello_world() { ... } The async keyword modifies the function prototype to return a Future trait object. It then wraps the execution result in a new Future and returns it, roughly equivalent to: fn hello_world() -&gt; impl Future&lt;Output = ()&gt; { async { ... } } Note: The async block implements an anonymous Future trait object, encapsulating a Generator , which is a Future -implementing generator. A Generator essentially acts as a state machine. When any operation inside an async block returns Poll::Pending , the generator calls yield , relinquishing execution. Once resumed, the generator continues execution until all code completes, meaning the state machine enters the Complete state and returns Poll::Ready , signaling that the Future has finished execution. A code block marked with async is converted into a state machine that implements the Future trait. Unlike synchronous calls that block the current thread, when a Future encounters a blocking operation, it relinquishes control of the current thread, waiting for the execution result of other Future s. A Future needs to run on an executor. For example, block_on is an executor that blocks the current thread: // block_on blocks the current thread until the specified Future completes execution. // This approach is simple and direct, but other runtime executors provide more sophisticated behaviors, // such as using join to schedule multiple futures on the same thread. use futures::executor::block_on; async fn hello_world() { println!(&quot;hello, world!&quot;); } fn main() { let future = hello_world(); // Returns a Future, so no output is printed yet block_on(future); // Executes the Future and waits for it to complete; &quot;hello, world!&quot; is then printed } Using await to Wait for Another Asynchronous Future to Complete In the main function above, we used the block_on executor to wait for the Future to complete, making the code appear synchronous. But what if you need to call an async fn inside another async fn and wait for its completion before executing subsequent code? For example: use futures::executor::block_on; async fn hello_world() { // Directly calling another async function inside an async function-will this work? hello_cat(); println!(&quot;hello, world!&quot;); } async fn hello_cat() { println!(&quot;hello, kitty!&quot;); } fn main() { let future = hello_world(); block_on(future); } Here, in the hello_world async function, we first call another async function hello_cat and then print &quot;hello, world!&quot; . Let&#x27;s check the output: warning: unused implementer of `futures::Future` that must be used --&gt; src/main.rs:6:5 | 6 | hello_cat(); | ^^^^^^^^^^^^ = note: futures do nothing unless you `.await` or poll them ... hello, world! As expected, we executed the Future in main using block_on , but the Future returned by hello_cat was never executed. Fortunately, the compiler provides a friendly warning: &quot;Futures do nothing unless you .await or poll them.&quot; There are two solutions: Use .await syntax. Manually poll the Future (which is more complex, so we won’t cover it here). Let’s modify the code using .await : use futures::executor::block_on; async fn hello_world() { hello_cat().await; println!(&quot;hello, world!&quot;); } async fn hello_cat() { println!(&quot;hello, kitty!&quot;); } fn main() { let future = hello_world(); block_on(future); } After adding .await to hello_cat() , the output changes significantly: hello, kitty! hello, world! The output order now strictly follows the code order. This means that we achieved asynchronous execution while maintaining a sequential coding style. This approach is simple, efficient, and eliminates callback hell. Internally, every .await acts like an executor, repeatedly polling the Future state. If it returns Pending , it calls yield . Otherwise, it exits the loop and completes the Future execution. The logic is roughly as follows: loop { match some_future.poll() { Pending =&gt; yield, Ready(x) =&gt; break } } In short, using .await inside an async fn allows waiting for another asynchronous call to complete. However, unlike block_on , .await does not block the current thread. Instead, it asynchronously waits for Future A to complete. While waiting, the thread can continue executing other Future B instances, enabling concurrency. An Example Consider a scenario of singing and dancing. Without .await , the implementation might look like this: use futures::executor::block_on; struct Song { author: String, name: String, } async fn learn_song() -&gt; Song { Song { author: &quot;Rick Astley&quot;.to_string(), name: String::from(&quot;Never Gonna Give You Up&quot;), } } async fn sing_song(song: Song) { println!( &quot;Performing {}&#x27;s {} ~ {}&quot;, song.author, song.name, &quot;Never gonna let you down&quot; ); } async fn dance() { println!(&quot;Dancing along to the song&quot;); } fn main() { let song = block_on(learn_song()); // First blocking call block_on(sing_song(song)); // Second blocking call block_on(dance()); // Third blocking call } This code runs correctly but requires three consecutive blocking calls, completing one task at a time. In reality, we could sing and dance simultaneously: use futures::executor::block_on; struct Song { author: String, name: String, } async fn learn_song() -&gt; Song { Song { author: &quot;Rick Astley&quot;.to_string(), name: String::from(&quot;Never Gonna Give You Up&quot;), } } async fn sing_song(song: Song) { println!( &quot;Performing {}&#x27;s {} ~ {}&quot;, song.author, song.name, &quot;Never gonna let you down&quot; ); } async fn dance() { println!(&quot;Dancing along to the song&quot;); } async fn learn_and_sing() { let song = learn_song().await; sing_song(song).await; } async fn async_main() { let f1 = learn_and_sing(); let f2 = dance(); // The join! macro runs multiple futures concurrently futures::join!(f1, f2); } fn main() { block_on(async_main()); } Here, learning and singing have a strict order, but both can coexist with dancing. Without .await , using block_on(learn_song()) would block the current thread, preventing any other tasks, including dancing. Thus, .await is crucial for asynchronous programming in Rust. It allows multiple tasks to run concurrently on the same thread instead of executing sequentially. Conclusion async/.await is Rust&#x27;s built-in tool for writing asynchronous functions that look like synchronous code. async converts a code block into a state machine that implements the Future trait, which must run on an executor. Instead of blocking an entire thread, a Future yields control, allowing other Future s to execute. Key takeaways: Future represents a task that yields a value in the future. async creates a Future . .await polls a Future , waiting for it to complete. Executors (like block_on ) manage and execute Future s. Rust’s async is zero-cost: no heap allocation or dynamic dispatch. Rust does not include a built-in async runtime; third-party libraries like tokio , async-std , and smol provide this functionality. In summary, async/.await enables efficient, concurrent task execution in Rust, eliminating callback hell and making asynchronous programming intuitive. We are Leapcell, your top choice for hosting Rust projects. Leapcell is the Next-Gen Serverless Platform for Web Hosting, Async Tasks, and Redis: Multi-Language Support Develop with Node.js, Python, Go, or Rust. Deploy unlimited projects for free pay only for usage — no requests, no charges. Unbeatable Cost Efficiency Pay-as-you-go with no idle charges. Example: $25 supports 6.94M requests at a 60ms average response time. Streamlined Developer Experience Intuitive UI for effortless setup. Fully automated CI/CD pipelines and GitOps integration. Real-time metrics and logging for actionable insights. Effortless Scalability and High Performance Auto-scaling to handle high concurrency with ease. Zero operational overhead — just focus on building. Explore more in the Documentation ! Follow us on X: @LeapcellHQ Read on our blog Web Development Programming Backend Rust -- -- Written by Leapcell 395 followers · 1 following leapcell.io , web hosting / async task / redis No responses yet Help Status About Careers Press Blog Privacy Rules Terms Text to speech

**Confidence**: 0.80

## Sources

1. [Fundamentals of Asynchronous Programming: Async, Await ... - Learn Rust](https://doc.rust-lang.org/book/ch17-00-async-await.html) - Relevance: 0.80
   > DuckDuckGo result for: Rust async programming

2. [Introduction - Async programming in Rust with async-std](https://book.async.rs/) - Relevance: 0.80
   > DuckDuckGo result for: Rust async programming

3. [Async/Await in Rust: A Beginner&#x27;s Guide | by Leapcell | Medium](https://leapcell.medium.com/async-await-in-rust-a-beginners-guide-8752d2c2abbf) - Relevance: 0.80
   > DuckDuckGo result for: Rust async programming

